{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200e59ac",
   "metadata": {},
   "source": [
    "# Neural network for determining the sign of the sum of two numbers\n",
    "### by Börge Göbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed6b4",
   "metadata": {},
   "source": [
    "## 1 . Prepare training and test data (typically loaded from file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a448f",
   "metadata": {},
   "source": [
    "- Here we generate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f275a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeData = 20                             # Numbers from [-rangeData,+rangeData]\n",
    "lenData = 1000                             # How many pairs of numbers do we generate\n",
    "testProportion = 0.3                       # 30% testing, 70% training \n",
    "testEnd = round(lenData * testProportion)  # How many pairs of numbers are used for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b051c",
   "metadata": {},
   "source": [
    "- Generate 1000 pairs of numbers as 1000 seperate inputs for our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIn = np.random.randint(-rangeData, rangeData+1, size=(lenData, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea58ac4",
   "metadata": {},
   "source": [
    "- Generate the corresponding 1000 output values. These will be the sum of the two inputs.\n",
    "- We do not tell the network that it is the sum. The network shall learn this by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f203982",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "dataOut = dataIn[:,0] + dataIn[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87b0a9",
   "metadata": {},
   "source": [
    "Sort them into categories [negative, positive]\n",
    "\n",
    "-1 (negative) \\\\(\\rightarrow \\\\) [1,0]\n",
    "\n",
    "+1 (positive) \\\\(\\rightarrow \\\\) [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105c59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "424a0dfa",
   "metadata": {},
   "source": [
    "- Adding a '1' element to each input pair (related to bias - more on this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f61df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIn = np.concatenate([np.ones([lenData,1]), dataIn], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f800a",
   "metadata": {},
   "source": [
    "- The final data sets and 1 example each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3582142",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingIn   = dataIn[0:testEnd]\n",
    "testingOut  = dataOut[0:testEnd]\n",
    "trainingIn  = dataIn[testEnd:]\n",
    "trainingOut = dataOut[testEnd:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ba63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( testingIn[0] )\n",
    "print( testingOut[0] )\n",
    "print( trainingIn[0] )\n",
    "print( trainingOut[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c4320",
   "metadata": {},
   "source": [
    "## 2. Setting up neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b5b60f",
   "metadata": {},
   "source": [
    "![Sign_network.png](Sign_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e43ab7",
   "metadata": {},
   "source": [
    "Input layer length: 3 (1 bias + 2 numbers)\n",
    "\n",
    "Hidden layer length: 5 (5 neurons) \\\\( \\rightarrow\\\\) We can change this value to improve performance\n",
    "\n",
    "Output layer length: 2 (result catergories - negative vs positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6c678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01a265f3",
   "metadata": {},
   "source": [
    "### 2.1 Initialize weights: Numbers in the range from -2 to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281329",
   "metadata": {},
   "source": [
    "- We need a starting point for our weights. Let's select them randomly.\n",
    "- Be careful about the dimension of the arrays:\n",
    "\n",
    "    - weights[0] connects the input layer with the hidden layer\n",
    "    - weights[1] connects the hidden layer with the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "weights = 4 * np.random.random_sample(3) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038dc2b",
   "metadata": {},
   "source": [
    "### 2.2 Activation function\n",
    "\n",
    "- Typically a monotonuous function that rescales a value to the range [0,1]\n",
    "- Here we use the sigmoid function:\n",
    "\n",
    "Activation function:\n",
    "\\\\( a(x) = \\frac{1}{1+\\exp(-x)} \\\\)\n",
    "\n",
    "Derivative:\n",
    "\\\\( a'(x) = \\frac{\\exp(-x)}{\\left[1+\\exp(-x)\\right]^2} \\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb3617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07cea533",
   "metadata": {},
   "source": [
    "### 2.3 Calculate output of our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35646410",
   "metadata": {},
   "source": [
    "The value of a neuron is given as the dot product of the two vectors: \n",
    "- weights \n",
    "- value of the neurons in the previous layer (including bias: value 1)\n",
    "\n",
    "This value is then rescaled by the activation function.\n",
    "\n",
    "First, calculate the hidden layer:\n",
    "\\\\( h_i = a\\left(w_{0i}^{(0)}x_0 + w_{1i}^{(0)}x_1 + w_{2i}^{(0)}x_2\\right) \\\\)\n",
    "\n",
    "Then, calculate the output layer:\n",
    "\\\\( y_j = a\\left(w_{0j}^{(1)}h_0 + w_{1j}^{(1)}h_1 + w_{2j}^{(1)}h_2 + w_{3j}^{(1)}h_3 + w_{4j}^{(1)}h_4 \\right) \\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "def calculateOut(x,w):\n",
    "    # x: input\n",
    "    # w: weights\n",
    "    return np.dot(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "testIndex = 10\n",
    "calculateOut( trainingIn[testIndex], weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67ab12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f151ca3",
   "metadata": {},
   "source": [
    "The calculation of one of these output values corresponds to:\n",
    "\n",
    "\\\\( y_j = a\\Big[w_{0j}^{(1)}a\\left(w_{00}^{(0)}x_0 + w_{10}^{(0)}x_1 + w_{20}^{(0)}x_2\\right) \\\\ \\quad\\quad + w_{1j}^{(1)}a\\left(w_{01}^{(0)}x_0 + w_{11}^{(0)}x_1 + w_{21}^{(0)}x_2\\right) \\\\ \\quad\\quad + w_{2j}^{(1)}a\\left(w_{02}^{(0)}x_0 + w_{12}^{(0)}x_1 + w_{22}^{(0)}x_2\\right) \\\\ \\quad\\quad + w_{3j}^{(1)}a\\left(w_{03}^{(0)}x_0 + w_{13}^{(0)}x_1 + w_{23}^{(0)}x_2\\right) \\\\ \\quad\\quad + w_{4j}^{(1)}a\\left(w_{04}^{(0)}x_0 + w_{14}^{(0)}x_1 + w_{24}^{(0)}x_2\\right) \\Big] \\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e9159",
   "metadata": {},
   "source": [
    "### 2.4 Functions: Calculate accuracy and individual error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942ca8a",
   "metadata": {},
   "source": [
    "### - Accuracy: \n",
    "What is the rate at which the output is predicted correctly (only correct and wrong matter)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "def accuracy(testingIn,testingOut,weights):\n",
    "    return 1 - np.sum( \n",
    "                np.abs( \n",
    "                    np.sign (\n",
    "                        np.round( calculateOut( testingIn, weights )) - testingOut \n",
    "                    ) ) ) / testEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(testingIn,testingOut,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237560c",
   "metadata": {},
   "source": [
    "- So far, output is random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6956b8",
   "metadata": {},
   "source": [
    "### - Error (better for learning): \n",
    "For each input the 2 component output vector is compared to the correct 2 component output vector\n",
    "\n",
    "\\\\( \\Delta = (\\vec{y}-\\vec{Y})^2=\\sum_j (y_j-Y_j)^2 \\\\)\n",
    "\n",
    "\\\\( y_j \\\\): Predicted output of neuron \\\\( j \\\\) (Number between 0 and 1)\n",
    "\n",
    "\\\\( Y_j \\\\): Correct result of neuron \\\\( j \\\\) (Number exactly 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2330e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(predictedValues, correctValues):\n",
    "    return np.sum(predictedValues - correctValues)**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "error(calculateOut(trainingIn[testIndex], weights), trainingOut[testIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fcb84",
   "metadata": {},
   "source": [
    "Or as one long formula\n",
    "\n",
    "\\\\(\\Delta = \\sum_j \\Big( a\\Big[w_{0j}^{(1)}a\\left(w_{00}^{(0)}x_0 + w_{10}^{(0)}x_1 + w_{20}^{(0)}x_2\\right) \\\\ \\quad\\quad\\quad\\quad + w_{1j}^{(1)}a\\left(w_{01}^{(0)}x_0 + w_{11}^{(0)}x_1 + w_{21}^{(0)}x_2\\right) \\\\ \\quad\\quad\\quad\\quad + w_{2j}^{(1)}a\\left(w_{02}^{(0)}x_0 + w_{12}^{(0)}x_1 + w_{22}^{(0)}x_2\\right) \\\\ \\quad\\quad\\quad\\quad + w_{3j}^{(1)}a\\left(w_{03}^{(0)}x_0 + w_{13}^{(0)}x_1 + w_{23}^{(0)}x_2\\right) \\\\ \\quad\\quad\\quad\\quad + w_{4j}^{(1)}a\\left(w_{04}^{(0)}x_0 + w_{14}^{(0)}x_1 + w_{24}^{(0)}x_2\\right) \\Big] -Y_j\\Big)^2 \\\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f535da",
   "metadata": {},
   "source": [
    "### 2.5 Function: Calculate gradient (d Error / d weight)\n",
    "\n",
    "- All derivatives with respect to the individual weights (Use chain rule)\n",
    "\n",
    "\\\\( \\frac{\\partial }{\\partial w_{ij}^{(1)}}\\Delta = 2(y_j-Y_j) \\cdot a'\\left(w_{0j}^{(1)}h_0 + w_{1j}^{(1)}h_1 + w_{2j}^{(1)}h_2 + w_{3j}^{(1)}h_3 + w_{4j}^{(1)}h_4 \\right)\\cdot a\\left(w_{0i}^{(0)}x_0 + w_{1i}^{(0)}x_1 + w_{2i}^{(0)}x_2\\right)\\\\)\n",
    "\n",
    "\\\\( \\frac{\\partial }{\\partial w_{ki}^{(0)}}\\Delta = \\sum_j 2(y_j-Y_j) \\cdot a'\\left(w_{0j}^{(1)}h_0 + w_{1j}^{(1)}h_1 + w_{2j}^{(1)}h_2 + w_{3j}^{(1)}h_3 + w_{4j}^{(1)}h_4 \\right)\\cdot w_{ij}^{(1)} \\cdot a'\\left(w_{0i}^{(0)}x_0 + w_{1i}^{(0)}x_1 + w_{2i}^{(0)}x_2\\right)\\cdot x_k\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "def gradient(x,w,correctValues):\n",
    "    return 2 * (calculateOut(x,w) - correctValues) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(trainingIn[testIndex], weights, trainingOut[testIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ebe73",
   "metadata": {},
   "source": [
    "## 3. Training: Use Gradient descent to change weights to minimize the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e85b48",
   "metadata": {},
   "source": [
    "Repeat the following process many time:\n",
    "- Select an input pair (index)\n",
    "- Calculate the gradient of the error \n",
    "- Change weights accoding to \n",
    "\n",
    "\\\\( w_\\mathrm{new} = w_\\mathrm{old} - learingRate\\cdot gradient\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e590f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "learningRate = 0.001\n",
    "steps = 10000\n",
    "\n",
    "# for documentation\n",
    "errorList = [error(calculateOut(trainingIn[testIndex], weights), trainingOut[testIndex])]\n",
    "weightList = [weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "for i in range(steps):\n",
    "    # pick random input\n",
    "    index = np.random.randint(lenData-testEnd)\n",
    "    # update weights (go along opposite gradient)\n",
    "    weights = weights - learningRate*gradient(trainingIn[index], weights, trainingOut[index])\n",
    "    weightList.append( weights )\n",
    "    # calculate new error\n",
    "    er = error(calculateOut(trainingIn[index], weights), trainingOut[index])\n",
    "    errorList.append( er )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f125c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(er)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58fdfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ylim([0,1])\n",
    "plt.scatter(range(steps+1),errorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34711374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(steps+1),np.log(errorList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4889936",
   "metadata": {},
   "source": [
    "## 4. Application to test data set (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8710b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "np.round(calculateOut( testingIn, weights ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afa2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE ###\n",
    "\n",
    "calculateOut( testingIn, weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dda08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(testingIn,testingOut,weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
